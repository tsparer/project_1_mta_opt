{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline  \n",
    "# above allows us to read charts in the python notebook:\n",
    "\n",
    "import datetime\n",
    "\n",
    "###########################\n",
    "# Importing turnstile data\n",
    "############################\n",
    "# Function that pulls data for a given week(s) (as list) on mta turnstyle use\n",
    "# returns dataframe of turnstyle data\n",
    "def get_data(week_nums):\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"  #mta website with data note the curly brackets\n",
    "    dfs = []                             # curly brackets, above, in string formatting, allow the code/user to insert a \n",
    "    print(dfs)                              # a different name into the variable- very useful for constructing structured datasets\n",
    "    for week in week_nums:\n",
    "        file_url = url.format(week) # the .format in conjunction with the string + brackets (above), allows for naming the files in standard manner\n",
    "        print (file_url)\n",
    "        dfs.append(pd.read_csv(file_url))   #uses readcsv functions from pd library to convert the url to a pandas dataframe, and adds it to the list of dfs)\n",
    "    return (pd.concat(dfs))  \n",
    "        # turns all of the dataframes in the list into one big dataframe.  Concat could be tricky,\n",
    "         # but its ok here, because the column names are all the same, and there are no duplicate date/times between the web pages from which these are pulled (double check this- assumption?)\n",
    "    \n",
    "week_nums = [160903, 160910, 160917]  # data to test the turnstyle func\n",
    "turnstiles_df = get_data(week_nums)\n",
    "turnstiles_df.head()\n",
    "turnstiles_df.tail()\n",
    "turnstiles_df.columns\n",
    "turnstiles_df.columns = [column.strip() for column in turnstiles_df.columns]\n",
    "turnstiles_df.head()\n",
    "\n",
    "# organize the data by date\n",
    "turnstiles_df.DATE.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mask = ((turnstiles_df[\"C/A\"] == \"R626\") & \n",
    "(turnstiles_df[\"UNIT\"] == \"R062\") & \n",
    "(turnstiles_df[\"SCP\"] == \"00-00-00\") & \n",
    "(turnstiles_df[\"STATION\"] == \"CROWN HTS-UTICA\"))\n",
    "\n",
    "turnstiles_df[mask].head()\n",
    "#pick a specific turnstile and check its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a unique ID based on the seperate column headings\n",
    "(turnstiles_df\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    "  .sort_values(\"ENTRIES\", ascending=False)).head(5)  # since groupby creates dictionaries with tuples (groups) as\n",
    "# keys and lists of the pandas series meeting those group-values as values\n",
    "# in this case, the count should be 1 for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove the single duplicate entry using .drop_duplicates\n",
    "turnstiles_df.drop_duplicates(subset=[\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=True)\n",
    "\n",
    "turnstiles_shifted = turnstiles_df.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"]).ENTRIES.first().reset_index()\n",
    "\n",
    "turnstiles_shifted.head(300)\n",
    "\n",
    "\n",
    "\n",
    "turnstiles_shifted[[\"PREV_DATE_TIME\", \"PREV_ENTRIES\"]] = (turnstiles_shifted\n",
    "                                                           .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])\n",
    "                                                            [\"DATE_TIME\", \"ENTRIES\"].transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "turnstiles_shifted.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "turnstiles_daily[[\"PREV_DATE\", \"PREV_ENTRIES\"]] = (turnstiles_daily\n",
    "                                                       .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"]\n",
    "                                                       .transform(lambda grp: grp.shift(1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
